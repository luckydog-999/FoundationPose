# # docker_server.py
# import socket
# import struct
# import json
# import numpy as np
# import cv2
# import lz4.frame
# import os
# import logging
# import torch
# import gc

# from ultralytics import YOLO
# from estimater import * 
# from datareader import *
# from my_utils.socket_utils import recv_msg, send_msg, recv_json, send_json, recvall

# torch.set_grad_enabled(False)
# HOST = '0.0.0.0'
# PORT = 6006

# OBJECT_CONFIG = {
#     "passive": {
#         "yolo_path": "passive_best.pt", 
#         "mesh_path": "./demo_data/passive/mesh/passive.obj", 
#     },
#     "insert": {
#         "yolo_path": "insert_best.pt",
#         "mesh_path": "./demo_data/insert/mesh/insert.obj", 
#     }
# }

# LOADED_OBJECTS = {} 
# g_K = None
# g_shape = None
# g_est_refine_iter = 1 

# def get_projected_corners(pose, bbox, K):
#     # (ä¿ç•™åŸå‡½æ•°ä¸å˜)
#     min_pt = bbox[0]
#     max_pt = bbox[1]
#     corners_3d = np.array([
#         [min_pt[0], min_pt[1], min_pt[2]],
#         [min_pt[0], min_pt[1], max_pt[2]],
#         [min_pt[0], max_pt[1], min_pt[2]],
#         [min_pt[0], max_pt[1], max_pt[2]],
#         [max_pt[0], min_pt[1], min_pt[2]],
#         [max_pt[0], min_pt[1], max_pt[2]],
#         [max_pt[0], max_pt[1], min_pt[2]],
#         [max_pt[0], max_pt[1], max_pt[2]]
#     ])
#     ones = np.ones((8, 1))
#     corners_hom = np.hstack((corners_3d, ones))
#     corners_cam = (pose @ corners_hom.T).T
#     corners_cam = corners_cam[:, :3]
#     projected = (K @ corners_cam.T).T
#     z = projected[:, 2:3] + 1e-5
#     pixels = projected[:, :2] / z
#     return pixels.astype(int).tolist()

# def load_models():
#     logging.info(">>> Loading models...")
#     for obj_name, config in OBJECT_CONFIG.items():
#         logging.info(f"--- Loading: [{obj_name}] ---")
#         if not os.path.exists(config["mesh_path"]) or not os.path.exists(config["yolo_path"]):
#             logging.error(f"âŒ File missing for {obj_name}")
#             continue

#         # åŠ è½½ Mesh
#         mesh = trimesh.load(config["mesh_path"])
#         to_origin, extents = trimesh.bounds.oriented_bounds(mesh)
#         bbox = np.stack([-extents/2, extents/2], axis=0).reshape(2,3)

#         # åˆå§‹åŒ– Estimater
#         scorer = ScorePredictor()
#         refiner = PoseRefinePredictor()
#         glctx = dr.RasterizeCudaContext()
#         est = FoundationPose(model_pts=mesh.vertices, model_normals=mesh.vertex_normals, 
#                              mesh=mesh, scorer=scorer, refiner=refiner, 
#                              debug_dir="./debug", debug=0, glctx=glctx)
        
#         yolo_model = YOLO(config["yolo_path"])

#         LOADED_OBJECTS[obj_name] = {
#             "est": est, "yolo": yolo_model, "to_origin": to_origin, "bbox": bbox
#         }
#         torch.cuda.empty_cache()
#     logging.info("âœ… Models Ready")

# def main():
#     global g_K, g_shape
#     logging.basicConfig(level=logging.INFO)
#     load_models()

#     server_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
#     server_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
#     server_sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1) 
#     server_sock.bind((HOST, PORT))
#     server_sock.listen(1)
#     print(f"ğŸš€ Docker Server listening on {PORT}...")

#     while True:
#         conn, addr = server_sock.accept()
#         print(f"Connected by {addr}")
        
#         try:
#             # Init
#             init_data = recv_json(conn)
#             if init_data and 'K' in init_data:
#                 g_K = np.array(init_data['K'])
#                 g_shape = tuple(init_data['shape'])
#                 print(f"Client Init: {g_shape}")
#                 send_json(conn, {"status": "ok"})
#             else:
#                 conn.close()
#                 continue

#             while True:
#                 header_data = recvall(conn, 12)
#                 if not header_data: break
#                 rgb_len, depth_len, type_len = struct.unpack('>III', header_data)
                
#                 type_bytes = recvall(conn, type_len)
#                 rgb_bytes = recvall(conn, rgb_len)
#                 depth_bytes = recvall(conn, depth_len)
#                 if not rgb_bytes: break

#                 target_type = type_bytes.decode('utf-8')
                
#                 # Check object
#                 if target_type not in LOADED_OBJECTS:
#                     print(f"Warning: Unknown target {target_type}")
#                     send_json(conn, {"found": False, "err": "Unknown Obj"})
#                     continue

#                 obj_data = LOADED_OBJECTS[target_type]
                
#                 # Decode
#                 img_bgr = cv2.imdecode(np.frombuffer(rgb_bytes, np.uint8), cv2.IMREAD_COLOR)
#                 color = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
                
#                 depth_raw = lz4.frame.decompress(depth_bytes)
#                 depth = np.frombuffer(depth_raw, dtype=np.float32).reshape(g_shape)

#                 # YOLO
#                 results = obj_data["yolo"](color, conf=0.5, verbose=False)
#                 mask = np.zeros(g_shape, dtype=bool)
                
#                 yolo_found = False
#                 if len(results[0].boxes) > 0:
#                     yolo_found = True
#                     if results[0].masks is not None:
#                         m_data = results[0].masks.data[0].cpu().numpy()
#                         if m_data.shape[:2] != color.shape[:2]:
#                             m_data = cv2.resize(m_data, (color.shape[1], color.shape[0]), interpolation=cv2.INTER_NEAREST)
#                         mask = m_data.astype(bool)
                
#                 if not yolo_found:
#                     # è°ƒè¯•ï¼šå‘Šè¯‰å®¢æˆ·ç«¯ YOLO æ²¡çœ‹åˆ°
#                     send_json(conn, {"found": False, "err": "YOLO Fail"})
#                     continue

#                 if mask.sum() < 50:
#                     send_json(conn, {"found": False, "err": "Mask too small"})
#                     continue

#                 try:
#                     pose = obj_data["est"].register(K=g_K, rgb=color, depth=depth, ob_mask=mask, iteration=g_est_refine_iter)
                    
#                     center_pose = pose @ np.linalg.inv(obj_data["to_origin"])
#                     corners_2d = get_projected_corners(center_pose, obj_data["bbox"], g_K)
                    
#                     send_json(conn, {
#                         "found": True,
#                         "pose": pose.tolist(),
#                         "corners": corners_2d
#                     })
#                 except Exception as e:
#                     print(f"Pose Error: {e}")
#                     # å¦‚æœå´©äº†ï¼Œè¿”å› False è€Œä¸æ˜¯æ–­å¼€è¿æ¥
#                     send_json(conn, {"found": False, "err": "Pose Calc Fail"})

#         except Exception as e:
#             print(f"Conn Error: {e}")
#         finally:
#             conn.close()

# if __name__ == '__main__':
#     main()

# # docker_server.py
# import socket
# import struct
# import json
# import numpy as np
# import cv2
# import lz4.frame
# import os
# import logging
# import torch
# import gc

# from ultralytics import YOLO
# from estimater import *
# from datareader import *
# from my_utils.socket_utils import recvall, send_json

# # --- æ˜¾å­˜æ•‘æ˜Ÿ ---
# torch.set_grad_enabled(False)
# HOST = '0.0.0.0'
# PORT = 6006

# # 4050 å¿…é¡»è®¾ä¸º 1ï¼Œå¦åˆ™æ˜¾å­˜çˆ†
# g_est_refine_iter = 1 

# OBJECT_CONFIG = {
#     "passive": {
#         "yolo_path": "passive_best.pt", 
#         "mesh_path": "./demo_data/passive/mesh/passive.obj", 
#     },
#     "insert": {
#         "yolo_path": "insert_best.pt",
#         "mesh_path": "./demo_data/insert/mesh/insert.obj", 
#     }
# }

# LOADED_OBJECTS = {}
# # è®°å½•ä¸Šä¸€å¸§çš„å§¿æ€ï¼Œç”¨äºè·Ÿè¸ª
# LAST_POSE = {"passive": None, "insert": None}

# def get_projected_corners(pose, bbox, K):
#     min_pt = bbox[0]
#     max_pt = bbox[1]
#     corners_3d = np.array([
#         [min_pt[0], min_pt[1], min_pt[2]],
#         [min_pt[0], min_pt[1], max_pt[2]],
#         [min_pt[0], max_pt[1], min_pt[2]],
#         [min_pt[0], max_pt[1], max_pt[2]],
#         [max_pt[0], min_pt[1], min_pt[2]],
#         [max_pt[0], min_pt[1], max_pt[2]],
#         [max_pt[0], max_pt[1], min_pt[2]],
#         [max_pt[0], max_pt[1], max_pt[2]]
#     ])
#     ones = np.ones((8, 1))
#     corners_hom = np.hstack((corners_3d, ones))
#     corners_cam = (pose @ corners_hom.T).T
#     corners_cam = corners_cam[:, :3]
#     projected = (K @ corners_cam.T).T
#     z = projected[:, 2:3] + 1e-5
#     pixels = projected[:, :2] / z
#     return pixels.astype(int).tolist()

# def load_models():
#     logging.info(">>> Loading models...")
#     for obj_name, config in OBJECT_CONFIG.items():
#         if not os.path.exists(config["mesh_path"]): continue
        
#         logging.info(f"Loading {obj_name}...")
#         mesh = trimesh.load(config["mesh_path"])
#         to_origin, extents = trimesh.bounds.oriented_bounds(mesh)
#         bbox = np.stack([-extents/2, extents/2], axis=0).reshape(2,3)

#         scorer = ScorePredictor()
#         refiner = PoseRefinePredictor()
#         glctx = dr.RasterizeCudaContext()
#         est = FoundationPose(model_pts=mesh.vertices, model_normals=mesh.vertex_normals, 
#                              mesh=mesh, scorer=scorer, refiner=refiner, 
#                              debug_dir="./debug", debug=0, glctx=glctx)
#         yolo = YOLO(config["yolo_path"])
#         LOADED_OBJECTS[obj_name] = {"est": est, "yolo": yolo, "to_origin": to_origin, "bbox": bbox}
#         torch.cuda.empty_cache()
#     logging.info("âœ… Ready")

# def main():
#     logging.basicConfig(level=logging.INFO)
#     load_models()
    
#     server_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
#     server_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
#     server_sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1) 
#     server_sock.bind((HOST, PORT))
#     server_sock.listen(1)
#     print(f"ğŸš€ Waiting for connection on {PORT}...")

#     while True:
#         conn, addr = server_sock.accept()
#         print(f"Connected: {addr}")
        
#         # æ¡æ‰‹
#         try:
#             init_data = json.loads(conn.recv(1024).decode())
#             g_K = np.array(init_data['K'])
#             g_shape = tuple(init_data['shape'])
#             conn.send(json.dumps({"status": "ok"}).encode())
#         except:
#             conn.close()
#             continue

#         while True:
#             try:
#                 # æ¥æ”¶å¤´
#                 header = recvall(conn, 12)
#                 if not header: break
#                 rgb_len, depth_len, type_len = struct.unpack('>III', header)
                
#                 # æ¥æ”¶ä½“
#                 type_bytes = recvall(conn, type_len)
#                 rgb_bytes = recvall(conn, rgb_len)
#                 depth_bytes = recvall(conn, depth_len)
                
#                 target = type_bytes.decode('utf-8')
#                 if target not in LOADED_OBJECTS: continue
#                 obj_data = LOADED_OBJECTS[target]

#                 # è§£ç 
#                 img = cv2.imdecode(np.frombuffer(rgb_bytes, np.uint8), cv2.IMREAD_COLOR)
#                 color = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#                 depth = np.frombuffer(lz4.frame.decompress(depth_bytes), dtype=np.float32).reshape(g_shape)

#                 pose = None
                
#                 # === ğŸš€ æ ¸å¿ƒç­–ç•¥: å…ˆå°è¯•è·Ÿè¸ª (Track) ===
#                 if LAST_POSE[target] is not None:
#                     try:
#                         # ä½¿ç”¨ä¸Šä¸€å¸§çš„å§¿æ€è¿›è¡Œå¾®è°ƒï¼Œä¸éœ€è¦ YOLOï¼Œé€Ÿåº¦æå¿«
#                         pose = obj_data["est"].track(K=g_K, rgb=color, depth=depth, 
#                                                      pose=LAST_POSE[target], iteration=g_est_refine_iter)
                        
#                         # é˜²ä¸¢æ£€æµ‹ï¼šå¦‚æœå§¿æ€å¤ªç¦»è°±(æ¯”å¦‚è·‘åˆ°ç›¸æœºåé¢å»äº†)ï¼Œè®¤ä¸ºä¸¢å¤±
#                         if np.isnan(pose).any() or pose[2,3] < 0.1:
#                             pose = None
#                             LAST_POSE[target] = None
#                             print(f"[{target}] Lost track, resetting...")
#                     except:
#                         pose = None
#                         LAST_POSE[target] = None

#                 # === ğŸ¢ å¤‡ç”¨ç­–ç•¥: è·Ÿè¸ªå¤±è´¥ï¼Œä½¿ç”¨ YOLO é‡æ£€æµ‹ ===
#                 if pose is None:
#                     # YOLO ä¹Ÿæ˜¯å¤§æ¶ˆè€—ï¼Œåªåœ¨ä¸¢å¤±æ—¶è¿è¡Œ
#                     res = obj_data["yolo"](color, conf=0.5, verbose=False)
#                     mask = None
#                     if len(res[0].boxes) > 0 and res[0].masks:
#                         m = res[0].masks.data[0].cpu().numpy()
#                         if m.shape[:2] != color.shape[:2]:
#                             m = cv2.resize(m, (color.shape[1], color.shape[0]), interpolation=cv2.INTER_NEAREST)
#                         mask = m.astype(bool)
                    
#                     if mask is not None and mask.sum() > 100:
#                         try:
#                             pose = obj_data["est"].register(K=g_K, rgb=color, depth=depth, ob_mask=mask, iteration=g_est_refine_iter)
#                         except: pass

#                 # === å‘é€ç»“æœ ===
#                 if pose is not None:
#                     LAST_POSE[target] = pose # æ›´æ–°è¿™ä¸€å¸§ï¼Œç»™ä¸‹ä¸€å¸§ç”¨
#                     center = pose @ np.linalg.inv(obj_data["to_origin"])
#                     corns = get_projected_corners(center, obj_data["bbox"], g_K)
#                     send_json(conn, {"found": True, "pose": pose.tolist(), "corners": corns})
#                     print(f"\r[{target}] Tracking... Z={pose[2,3]:.2f}", end="")
#                 else:
#                     send_json(conn, {"found": False})
#                     print(f"\r[{target}] Searching...", end="")

#             except Exception as e:
#                 print(e)
#                 break
        
#         conn.close()
#         LAST_POSE["passive"] = None
#         LAST_POSE["insert"] = None

# if __name__ == '__main__':
#     main()

import socket
import struct
import json
import numpy as np
import cv2
import lz4.frame
import os
import logging
import torch
import gc
import time

from ultralytics import YOLO
from estimater import *
from datareader import *
# å‡è®¾ä½ çš„ recvall, send_json åœ¨è¿™é‡Œï¼Œå¦‚æœæŠ¥é”™è¯·æŠŠå·¥å…·å‡½æ•°è´´è¿›æ¥
from my_utils.socket_utils import recvall, send_json

# --- ğŸ”¥ æ˜¾å­˜ä¸é€Ÿåº¦ä¼˜åŒ–é…ç½® ---
torch.set_grad_enabled(False)
HOST = '0.0.0.0'
PORT = 6006

# 4050 æ˜¾å¡æ˜¾å­˜è¾ƒå°ï¼Œä¿æŒä¸º 1 æœ€å¿«ï¼Œå¦‚æœæŠ–åŠ¨å‰å®³å¯æ”¹ä¸º 2
g_est_refine_iter = 1 

OBJECT_CONFIG = {
    "passive": {
        "yolo_path": "passive_best.pt", 
        "mesh_path": "./demo_data/passive/mesh/passive.obj", 
    },
    "insert": {
        "yolo_path": "insert_best.pt",
        "mesh_path": "./demo_data/insert/mesh/insert.obj", 
    }
}

LOADED_OBJECTS = {}
# å…¨å±€å˜é‡è®°å½•ä¸Šä¸€å¸§å§¿æ€
LAST_POSE = {"passive": None, "insert": None}

def get_projected_corners(pose, bbox, K):
    min_pt = bbox[0]
    max_pt = bbox[1]
    corners_3d = np.array([
        [min_pt[0], min_pt[1], min_pt[2]],
        [min_pt[0], min_pt[1], max_pt[2]],
        [min_pt[0], max_pt[1], min_pt[2]],
        [min_pt[0], max_pt[1], max_pt[2]],
        [max_pt[0], min_pt[1], min_pt[2]],
        [max_pt[0], min_pt[1], max_pt[2]],
        [max_pt[0], max_pt[1], min_pt[2]],
        [max_pt[0], max_pt[1], max_pt[2]]
    ])
    ones = np.ones((8, 1))
    corners_hom = np.hstack((corners_3d, ones))
    corners_cam = (pose @ corners_hom.T).T
    corners_cam = corners_cam[:, :3]
    projected = (K @ corners_cam.T).T
    z = projected[:, 2:3] + 1e-5
    pixels = projected[:, :2] / z
    return pixels.astype(int).tolist()

def load_models():
    logging.info(">>> Loading models...")
    for obj_name, config in OBJECT_CONFIG.items():
        if not os.path.exists(config["mesh_path"]): continue
        
        logging.info(f"Loading {obj_name}...")
        mesh = trimesh.load(config["mesh_path"])
        to_origin, extents = trimesh.bounds.oriented_bounds(mesh)
        bbox = np.stack([-extents/2, extents/2], axis=0).reshape(2,3)

        scorer = ScorePredictor()
        refiner = PoseRefinePredictor()
        glctx = dr.RasterizeCudaContext()
        est = FoundationPose(model_pts=mesh.vertices, model_normals=mesh.vertex_normals, 
                             mesh=mesh, scorer=scorer, refiner=refiner, 
                             debug_dir="./debug", debug=0, glctx=glctx)
        
        # é¢„åŠ è½½ YOLO åˆ° GPU
        yolo = YOLO(config["yolo_path"])
        
        LOADED_OBJECTS[obj_name] = {"est": est, "yolo": yolo, "to_origin": to_origin, "bbox": bbox}
        torch.cuda.empty_cache()
    logging.info("âœ… Models Ready")

def main():
    logging.basicConfig(level=logging.INFO)
    load_models()
    
    server_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    server_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    server_sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1) 
    server_sock.bind((HOST, PORT))
    server_sock.listen(1)
    print(f"ğŸš€ High-Speed Server listening on {PORT}...")

    while True:
        conn, addr = server_sock.accept()
        print(f"Connected: {addr}")
        
        # æ¡æ‰‹
        try:
            init_data = json.loads(conn.recv(1024).decode())
            g_K = np.array(init_data['K'])
            g_shape = tuple(init_data['shape'])
            conn.send(json.dumps({"status": "ok"}).encode())
        except Exception as e:
            print(f"Handshake error: {e}")
            conn.close()
            continue

        while True:
            try:
                # 1. æ¥æ”¶å¤´
                header = recvall(conn, 12)
                if not header: break
                rgb_len, depth_len, type_len = struct.unpack('>III', header)
                
                # 2. æ¥æ”¶ä½“
                type_bytes = recvall(conn, type_len)
                rgb_bytes = recvall(conn, rgb_len)
                depth_bytes = recvall(conn, depth_len)
                
                target = type_bytes.decode('utf-8')
                if target not in LOADED_OBJECTS: continue
                obj_data = LOADED_OBJECTS[target]

                # 3. è§£ç  (CPU è€—æ—¶ç‚¹ï¼Œä½†å¿…é¡»åš)
                img = cv2.imdecode(np.frombuffer(rgb_bytes, np.uint8), cv2.IMREAD_COLOR)
                color = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                depth = np.frombuffer(lz4.frame.decompress(depth_bytes), dtype=np.float32).reshape(g_shape)

                pose = None
                status_msg = "Searching"

                # =========================================================
                # ğŸš€ é«˜é€Ÿé€šé“ (Fast Track Mode)
                # =========================================================
                if LAST_POSE[target] is not None:
                    try:
                        # ç›´æ¥åŸºäºä¸Šä¸€å¸§å§¿æ€è¿›è¡Œ Refineï¼Œè·³è¿‡ YOLO
                        pose = obj_data["est"].track(K=g_K, rgb=color, depth=depth, 
                                                     pose=LAST_POSE[target], iteration=g_est_refine_iter)
                        
                        # --- ğŸ›¡ï¸ é˜²ä¸¢æ£€æµ‹ (Sanity Check) ---
                        # 1. æ£€æŸ¥ NaN
                        if np.isnan(pose).any():
                            raise ValueError("Pose implies NaN")
                        
                        # 2. æ£€æŸ¥è·ç¦» (é˜²æ­¢é£åˆ°æ— ç©·è¿œæˆ–ç›¸æœºèƒŒå)
                        # pose[2, 3] æ˜¯ç‰©ä½“åœ¨ç›¸æœºåæ ‡ç³»ä¸‹çš„ Z è½´è·ç¦» (ç±³)
                        if pose[2, 3] < 0.1 or pose[2, 3] > 3.0:
                            raise ValueError(f"Z-distance abnormal: {pose[2,3]:.2f}")

                        # 3. (å¯é€‰) æ£€æŸ¥ç¬ç§»ï¼šå¦‚æœä¸¤å¸§ä¹‹é—´ç§»åŠ¨è¶…è¿‡ 20cmï¼Œè®¤ä¸ºè·Ÿè¸ªå¤±æ•ˆ
                        prev_trans = LAST_POSE[target][:3, 3]
                        curr_trans = pose[:3, 3]
                        dist = np.linalg.norm(curr_trans - prev_trans)
                        if dist > 0.2: 
                            raise ValueError(f"Moved too fast: {dist:.2f}m")

                        status_msg = "Tracking"
                        
                    except Exception as e:
                        # è·Ÿè¸ªå¤±è´¥ï¼Œé™çº§å›æ£€æµ‹æ¨¡å¼
                        # print(f"[{target}] Lost track: {e}")
                        pose = None
                        LAST_POSE[target] = None
                        status_msg = "Lost"

                # =========================================================
                # ğŸ¢ æ…¢é€Ÿé€šé“ (Detection Mode) - åªæœ‰è·Ÿè¸ªä¸¢äº†æ‰è·‘
                # =========================================================
                if pose is None:
                    # è¿è¡Œ YOLO
                    res = obj_data["yolo"](color, conf=0.5, verbose=False)
                    mask = None
                    if len(res[0].boxes) > 0 and res[0].masks:
                        # æ‰¾æœ€å¤§çš„ mask æˆ–è€…ç½®ä¿¡åº¦æœ€é«˜çš„
                        m = res[0].masks.data[0].cpu().numpy()
                        if m.shape[:2] != color.shape[:2]:
                            m = cv2.resize(m, (color.shape[1], color.shape[0]), interpolation=cv2.INTER_NEAREST)
                        mask = m.astype(bool)
                    
                    if mask is not None and mask.sum() > 50:
                        try:
                            # é‡æ–°æ³¨å†Œå§¿æ€ (Register)
                            pose = obj_data["est"].register(K=g_K, rgb=color, depth=depth, ob_mask=mask, iteration=g_est_refine_iter)
                            status_msg = "Detected"
                        except: 
                            pass

                # =========================================================
                # ğŸ“¤ ç»“æœå‘é€
                # =========================================================
                if pose is not None:
                    LAST_POSE[target] = pose # æ›´æ–°ä¸Šä¸€å¸§ï¼Œä¾›ä¸‹ä¸€å¸§ Tracking ä½¿ç”¨
                    
                    # è¿™é‡Œçš„ pose æ˜¯ Model -> Camera
                    # æˆ‘ä»¬éœ€è¦æŠŠ bbox å˜æ¢åå‘å›å»
                    center_pose = pose @ np.linalg.inv(obj_data["to_origin"])
                    corns = get_projected_corners(center_pose, obj_data["bbox"], g_K)
                    
                    send_json(conn, {"found": True, "pose": pose.tolist(), "corners": corns})
                    print(f"\r[{target}] {status_msg} | Z={pose[2,3]:.3f}m", end="")
                else:
                    LAST_POSE[target] = None # ç¡®ä¿ä¸‹ä¸€å¸§é‡æ–°æ£€æµ‹
                    send_json(conn, {"found": False})
                    print(f"\r[{target}] Searching...", end="")

            except Exception as e:
                print(f"\nLoop Error: {e}")
                import traceback
                traceback.print_exc()
                break
        
        conn.close()
        # æ–­å¼€è¿æ¥æ—¶æ¸…ç†æ˜¾å­˜
        LAST_POSE["passive"] = None
        LAST_POSE["insert"] = None
        torch.cuda.empty_cache()
        print("\nConnection closed. VRAM cleared.")

if __name__ == '__main__':
    main()